// Template file for generating the model specification.
// This file has been automatically generated by Jinja2 via the
// script generate_models.py.
// Please do not change this file by hand.
use crate::{
    activation_functions::{GdnLayer, IgdnLayer, ReluLayer},
    convolutions::{ConvolutionLayer, Padding},
    transposed_convolutions::TransposedConvolutionLayer,
    weight_loader::WeightLoader,
    ImagePrecision,
};
use ndarray::*;

pub type InternalDataRepresentation = Array3<ImagePrecision>;

// A note on the weights:
// Naming convention:
// [architecture]_[coder]_[layer type]_[layer]_[weight type]

/// General model trait for en- and decoding
pub trait CodingModel {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation;
}

impl CodingModel for ConvolutionLayer {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        self.convolve(input)
    }
}

impl CodingModel for TransposedConvolutionLayer {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        self.transposed_convolve(input)
    }
}

impl CodingModel for GdnLayer {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        self.activate(input)
    }
}

impl CodingModel for IgdnLayer {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        self.activate(input)
    }
}

impl CodingModel for ReluLayer {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        self.activate(input)
    }
}

pub struct MinnenEncoder {
    layer_1: ConvolutionLayer,

    activation_1: GdnLayer,

    layer_2: ConvolutionLayer,

    activation_2: GdnLayer,

    layer_3: ConvolutionLayer,
}

impl CodingModel for MinnenEncoder {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        let x = input.clone();

        let x = self.layer_1.forward_pass(&x);

        let x = self.activation_1.forward_pass(&x);

        let x = self.layer_2.forward_pass(&x);

        let x = self.activation_2.forward_pass(&x);

        let x = self.layer_3.forward_pass(&x);

        x
    }
}

impl MinnenEncoder {
    pub fn new(loader: &mut impl WeightLoader) -> Self {
        let layer_1_weights = loader
            .get_weight("analysis_transform/layer_1/kernel_rdft", (192, 3, 5, 5))
            .unwrap();
        let layer_1 = ConvolutionLayer::new(layer_1_weights, 2, Padding::Same);

        let activation_1_weight_1 = loader
            .get_weight("analysis_transform/layer_1/gdn/gamma", 192)
            .unwrap();

        let activation_1_weight_2 = loader
            .get_weight("analysis_transform/layer_1/gdn/beta", (192, 192))
            .unwrap();

        let activation_1 = GdnLayer::new(activation_1_weight_1, activation_1_weight_2);

        let layer_2_weights = loader
            .get_weight("analysis_transform/layer_2/kernel_rdft", (192, 192, 5, 5))
            .unwrap();
        let layer_2 = ConvolutionLayer::new(layer_2_weights, 2, Padding::Same);

        let activation_2_weight_1 = loader
            .get_weight("analysis_transform/layer_2/gdn/gamma", 192)
            .unwrap();

        let activation_2_weight_2 = loader
            .get_weight("analysis_transform/layer_2/gdn/beta", (192, 192))
            .unwrap();

        let activation_2 = GdnLayer::new(activation_2_weight_1, activation_2_weight_2);

        let layer_3_weights = loader
            .get_weight("analysis_transform/layer_3/kernel_rdft", (192, 192, 5, 5))
            .unwrap();
        let layer_3 = ConvolutionLayer::new(layer_3_weights, 2, Padding::Same);

        Self {
            layer_1,

            activation_1,

            layer_2,

            activation_2,

            layer_3,
        }
    }
}

pub struct JohnstonDecoder {
    layer_1: TransposedConvolutionLayer,

    activation_1: IgdnLayer,

    layer_2: TransposedConvolutionLayer,

    activation_2: IgdnLayer,

    layer_3: TransposedConvolutionLayer,

    activation_3: IgdnLayer,

    layer_4: TransposedConvolutionLayer,
}

impl CodingModel for JohnstonDecoder {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        let x = input.clone();

        let x = self.layer_1.forward_pass(&x);

        let x = self.activation_1.forward_pass(&x);

        let x = self.layer_2.forward_pass(&x);

        let x = self.activation_2.forward_pass(&x);

        let x = self.layer_3.forward_pass(&x);

        let x = self.activation_3.forward_pass(&x);

        let x = self.layer_4.forward_pass(&x);

        x
    }
}

impl JohnstonDecoder {
    pub fn new(loader: &mut impl WeightLoader) -> Self {
        let layer_1_weights = loader
            .get_weight("synthesis_transform/layer_1/kernel_rdft", (79, 192, 5, 5))
            .unwrap();
        let layer_1 = TransposedConvolutionLayer::new(layer_1_weights, 2, Padding::Same);

        let activation_1_weight_1 = loader
            .get_weight("synthesis_transform/layer_1/igdn/gamma", 79)
            .unwrap();

        let activation_1_weight_2 = loader
            .get_weight("synthesis_transform/layer_1/igdn/beta", (79, 79))
            .unwrap();

        let activation_1 = IgdnLayer::new(activation_1_weight_1, activation_1_weight_2);

        let layer_2_weights = loader
            .get_weight("synthesis_transform/layer_2/kernel_rdft", (22, 79, 5, 5))
            .unwrap();
        let layer_2 = TransposedConvolutionLayer::new(layer_2_weights, 2, Padding::Same);

        let activation_2_weight_1 = loader
            .get_weight("synthesis_transform/layer_2/igdn/gamma", 22)
            .unwrap();

        let activation_2_weight_2 = loader
            .get_weight("synthesis_transform/layer_2/igdn/beta", (22, 22))
            .unwrap();

        let activation_2 = IgdnLayer::new(activation_2_weight_1, activation_2_weight_2);

        let layer_3_weights = loader
            .get_weight("synthesis_transform/layer_3/kernel_rdft", (43, 22, 5, 5))
            .unwrap();
        let layer_3 = TransposedConvolutionLayer::new(layer_3_weights, 2, Padding::Same);

        let activation_3_weight_1 = loader
            .get_weight("synthesis_transform/layer_3/igdn/gamma", 43)
            .unwrap();

        let activation_3_weight_2 = loader
            .get_weight("synthesis_transform/layer_3/igdn/beta", (43, 43))
            .unwrap();

        let activation_3 = IgdnLayer::new(activation_3_weight_1, activation_3_weight_2);

        let layer_4_weights = loader
            .get_weight("synthesis_transform/layer_4/kernel_rdft", (3, 43, 5, 5))
            .unwrap();
        let layer_4 = TransposedConvolutionLayer::new(layer_4_weights, 2, Padding::Same);

        Self {
            layer_1,

            activation_1,

            layer_2,

            activation_2,

            layer_3,

            activation_3,

            layer_4,
        }
    }
}

pub struct MinnenHyperEncoder {
    layer_1: ConvolutionLayer,

    activation_1: ReluLayer,

    layer_2: ConvolutionLayer,

    activation_2: ReluLayer,

    layer_3: ConvolutionLayer,
}

impl CodingModel for MinnenHyperEncoder {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        let x = input.clone();

        let x = self.layer_1.forward_pass(&x);

        let x = self.activation_1.forward_pass(&x);

        let x = self.layer_2.forward_pass(&x);

        let x = self.activation_2.forward_pass(&x);

        let x = self.layer_3.forward_pass(&x);

        x
    }
}

impl MinnenHyperEncoder {
    pub fn new(loader: &mut impl WeightLoader) -> Self {
        let layer_1_weights = loader
            .get_weight(
                "hyper_analysis_transform/layer_1/kernel_rdft",
                (192, 192, 3, 3),
            )
            .unwrap();
        let layer_1 = ConvolutionLayer::new(layer_1_weights, 1, Padding::Same);

        let activation_1 = ReluLayer::new();

        let layer_2_weights = loader
            .get_weight(
                "hyper_analysis_transform/layer_2/kernel_rdft",
                (192, 192, 5, 5),
            )
            .unwrap();
        let layer_2 = ConvolutionLayer::new(layer_2_weights, 2, Padding::Same);

        let activation_2 = ReluLayer::new();

        let layer_3_weights = loader
            .get_weight(
                "hyper_analysis_transform/layer_3/kernel_rdft",
                (192, 192, 5, 5),
            )
            .unwrap();
        let layer_3 = ConvolutionLayer::new(layer_3_weights, 2, Padding::Same);

        Self {
            layer_1,

            activation_1,

            layer_2,

            activation_2,

            layer_3,
        }
    }
}

pub struct JohnstonHyperDecoder {
    layer_1: TransposedConvolutionLayer,

    activation_1: ReluLayer,

    layer_2: TransposedConvolutionLayer,

    activation_2: ReluLayer,

    layer_3: TransposedConvolutionLayer,
}

impl CodingModel for JohnstonHyperDecoder {
    fn forward_pass(&self, input: &InternalDataRepresentation) -> InternalDataRepresentation {
        let x = input.clone();

        let x = self.layer_1.forward_pass(&x);

        let x = self.activation_1.forward_pass(&x);

        let x = self.layer_2.forward_pass(&x);

        let x = self.activation_2.forward_pass(&x);

        let x = self.layer_3.forward_pass(&x);

        x
    }
}

impl JohnstonHyperDecoder {
    pub fn new(loader: &mut impl WeightLoader) -> Self {
        let layer_1_weights = loader
            .get_weight(
                "mb_t2018hyper_synthesis_transform/layer_1/kernel_rdft",
                (76, 192, 3, 3),
            )
            .unwrap();
        let layer_1 = TransposedConvolutionLayer::new(layer_1_weights, 2, Padding::Same);

        let activation_1 = ReluLayer::new();

        let layer_2_weights = loader
            .get_weight(
                "mb_t2018hyper_synthesis_transform/layer_2/kernel_rdft",
                (107, 76, 5, 5),
            )
            .unwrap();
        let layer_2 = TransposedConvolutionLayer::new(layer_2_weights, 2, Padding::Same);

        let activation_2 = ReluLayer::new();

        let layer_3_weights = loader
            .get_weight(
                "mb_t2018hyper_synthesis_transform/layer_3/kernel_rdft",
                (320, 107, 5, 5),
            )
            .unwrap();
        let layer_3 = TransposedConvolutionLayer::new(layer_3_weights, 1, Padding::Same);

        Self {
            layer_1,

            activation_1,

            layer_2,

            activation_2,

            layer_3,
        }
    }
}
